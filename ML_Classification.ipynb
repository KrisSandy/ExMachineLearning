{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/KrisSandy/MachineLearning/blob/master/ML_Classification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "blkY-k_h6sLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning | Classification"
      ]
    },
    {
      "metadata": {
        "id": "x8dITrSWBNf_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this assignment I have choosen scikit-learn library which is an open source package developed in python. scikit-learn along with other scientific packages in python provides powerful data structures and machine learning features which can be leveraged with ease.\n",
        "\n",
        "Besides readily available implementation of K nearest Neighbours algorithm, below are some of the main reasons for choosing scikit-learn\n",
        "\n",
        "\n",
        "1.   scikit-learn is open source package\n",
        "2.   Its regularly updated with more than 1 release per year which means the packages are up to date.\n",
        "3. Easy to use \n",
        "4. It has implementations for most of the machine learning tasks such as Clustering, Classification, Regression etc.\n",
        "5. Very good and up to date documentation available.\n",
        "\n",
        "scikit-learn offers below features:\n",
        "\n",
        "\n",
        "1.   Preprocessing - to transform, extract features and normalize the data\n",
        "2.   Functions to perform Classification, Regression, Clustering \n",
        "3. Dimensionality reduction \n",
        "4. Model Selection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Reference: https://www.oreilly.com/ideas/six-reasons-why-i-recommend-scikit-learn*\n",
        "\n",
        "*Reference: http://scikit-learn.org/stable/index.html*"
      ]
    },
    {
      "metadata": {
        "id": "odZw_zWzYT0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connecting with Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "jEaCinr99HbE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configuring Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "h2vSH1Bg6wLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "cad4bbe7-2858-4c60-b09b-5a2a90040105"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMuqOP02XQCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verify google drive connection"
      ]
    },
    {
      "metadata": {
        "id": "gSxQn7Qz4T13",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "metadata": {
        "id": "P0wq-zwm1k7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ka3S3uiYbvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Y86H9VtoXbiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Data in the dataset is seperated by tab. Each row represents an attribute and columns represent each individual patients. \n",
        "\n",
        "* In order to load the data into pandas dataframe, the file should be read using read_csv and use the seperator as tab ('\\t'). A transpose of the dataframe is required to bring the data into traditional format i.e. features in columns and observations (patients) in rows. \n",
        "\n",
        "* After getting the data in desired format, column names are added to give more sense and completeness to the dataframe.\n",
        "\n",
        "* Data and Response used to train and test the models should be in numbers as numpy arrays. So Autoimmune_Disease column needs to be coverted to 0 and 1 representing negative and positive respectively. "
      ]
    },
    {
      "metadata": {
        "id": "PMBsuaR79Pxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2012
        },
        "outputId": "a286b237-7459-404a-c9b8-651a65c11bd0"
      },
      "cell_type": "code",
      "source": [
        "fields = ['Age', 'Blood_Pressure', 'BMI', 'Plasma_level', 'Autoimmune_Disease', 'Adverse_events', 'Drug_in_serum', 'Liver_function', 'Activity_test', 'Secondary_test']\n",
        "autoimmune_data = pd.read_csv(r'/content/gdrive/My Drive/GYE06/CT475_ML/autoimmune.txt',\n",
        "                 sep='\\t',\n",
        "                 header=None\n",
        "                )\n",
        "autoimmune_data = autoimmune_data.transpose()\n",
        "autoimmune_data.columns = fields\n",
        "autoimmune_data['Autoimmune_Disease'] = autoimmune_data['Autoimmune_Disease'].map({'negative':0, 'positive':1})\n",
        "autoimmune_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Blood_Pressure</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Plasma_level</th>\n",
              "      <th>Autoimmune_Disease</th>\n",
              "      <th>Adverse_events</th>\n",
              "      <th>Drug_in_serum</th>\n",
              "      <th>Liver_function</th>\n",
              "      <th>Activity_test</th>\n",
              "      <th>Secondary_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>35.1</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>0.692</td>\n",
              "      <td>32</td>\n",
              "      <td>12.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>74</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0.527</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>70</td>\n",
              "      <td>30.8</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.597</td>\n",
              "      <td>26</td>\n",
              "      <td>22.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>64</td>\n",
              "      <td>34.9</td>\n",
              "      <td>59.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>0.725</td>\n",
              "      <td>18</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>76</td>\n",
              "      <td>53.2</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.759</td>\n",
              "      <td>56</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>62</td>\n",
              "      <td>25.1</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>1.268</td>\n",
              "      <td>18</td>\n",
              "      <td>16.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35</td>\n",
              "      <td>84</td>\n",
              "      <td>35</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>0.286</td>\n",
              "      <td>41</td>\n",
              "      <td>34.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22</td>\n",
              "      <td>78</td>\n",
              "      <td>34.6</td>\n",
              "      <td>43.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.101</td>\n",
              "      <td>27</td>\n",
              "      <td>31.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>29.7</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>45</td>\n",
              "      <td>0.293</td>\n",
              "      <td>28</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23</td>\n",
              "      <td>86</td>\n",
              "      <td>45.5</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0.127</td>\n",
              "      <td>36</td>\n",
              "      <td>30.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>21</td>\n",
              "      <td>66</td>\n",
              "      <td>28.1</td>\n",
              "      <td>44.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>94</td>\n",
              "      <td>0.167</td>\n",
              "      <td>23</td>\n",
              "      <td>31.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>28</td>\n",
              "      <td>70</td>\n",
              "      <td>31.6</td>\n",
              "      <td>81.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>105</td>\n",
              "      <td>0.268</td>\n",
              "      <td>18</td>\n",
              "      <td>16.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>54</td>\n",
              "      <td>78</td>\n",
              "      <td>35.2</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>126</td>\n",
              "      <td>0.692</td>\n",
              "      <td>29</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>25</td>\n",
              "      <td>68</td>\n",
              "      <td>31.9</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>106</td>\n",
              "      <td>0.591</td>\n",
              "      <td>30</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>43</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>0.43</td>\n",
              "      <td>33</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>42</td>\n",
              "      <td>78</td>\n",
              "      <td>46.7</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>48</td>\n",
              "      <td>0.261</td>\n",
              "      <td>40</td>\n",
              "      <td>17.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>21</td>\n",
              "      <td>52</td>\n",
              "      <td>24.6</td>\n",
              "      <td>49.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>0.637</td>\n",
              "      <td>15</td>\n",
              "      <td>17.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>58</td>\n",
              "      <td>27.7</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>1.6</td>\n",
              "      <td>24</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>23</td>\n",
              "      <td>74</td>\n",
              "      <td>33.6</td>\n",
              "      <td>53.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.404</td>\n",
              "      <td>30</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26</td>\n",
              "      <td>88</td>\n",
              "      <td>43.3</td>\n",
              "      <td>90.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>0.222</td>\n",
              "      <td>44</td>\n",
              "      <td>16.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>24</td>\n",
              "      <td>56</td>\n",
              "      <td>33.3</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1.251</td>\n",
              "      <td>30</td>\n",
              "      <td>11.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>24</td>\n",
              "      <td>64</td>\n",
              "      <td>33.2</td>\n",
              "      <td>58.5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>0.23</td>\n",
              "      <td>27</td>\n",
              "      <td>10.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>31</td>\n",
              "      <td>78</td>\n",
              "      <td>33.8</td>\n",
              "      <td>86.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>185</td>\n",
              "      <td>0.97</td>\n",
              "      <td>39</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>60</td>\n",
              "      <td>37.2</td>\n",
              "      <td>43.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>0.509</td>\n",
              "      <td>37</td>\n",
              "      <td>25.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>30.1</td>\n",
              "      <td>90.5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>495</td>\n",
              "      <td>0.615</td>\n",
              "      <td>36</td>\n",
              "      <td>12.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>51</td>\n",
              "      <td>72</td>\n",
              "      <td>25.8</td>\n",
              "      <td>83</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>175</td>\n",
              "      <td>0.587</td>\n",
              "      <td>19</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>37</td>\n",
              "      <td>58</td>\n",
              "      <td>29.5</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>0.287</td>\n",
              "      <td>28</td>\n",
              "      <td>24.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>29.9</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>156</td>\n",
              "      <td>0.722</td>\n",
              "      <td>18</td>\n",
              "      <td>29.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>78</td>\n",
              "      <td>39</td>\n",
              "      <td>60.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>0.261</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>21</td>\n",
              "      <td>62</td>\n",
              "      <td>22.1</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "      <td>0.207</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>23</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>55.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>182</td>\n",
              "      <td>0.138</td>\n",
              "      <td>13</td>\n",
              "      <td>35.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>24</td>\n",
              "      <td>88</td>\n",
              "      <td>44.5</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0.646</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>23</td>\n",
              "      <td>82</td>\n",
              "      <td>40.6</td>\n",
              "      <td>76.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>485</td>\n",
              "      <td>0.687</td>\n",
              "      <td>42</td>\n",
              "      <td>20.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>38.2</td>\n",
              "      <td>84</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>321</td>\n",
              "      <td>0.787</td>\n",
              "      <td>42</td>\n",
              "      <td>31.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>33</td>\n",
              "      <td>50</td>\n",
              "      <td>27.1</td>\n",
              "      <td>59.5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>176</td>\n",
              "      <td>1.318</td>\n",
              "      <td>22</td>\n",
              "      <td>27.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>55</td>\n",
              "      <td>72</td>\n",
              "      <td>37.7</td>\n",
              "      <td>51.5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>0.324</td>\n",
              "      <td>32</td>\n",
              "      <td>18.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>30.9</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>158</td>\n",
              "      <td>0.292</td>\n",
              "      <td>21</td>\n",
              "      <td>11.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>25</td>\n",
              "      <td>68</td>\n",
              "      <td>30.5</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>1.391</td>\n",
              "      <td>19</td>\n",
              "      <td>26.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>57</td>\n",
              "      <td>76</td>\n",
              "      <td>37.5</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>280</td>\n",
              "      <td>0.605</td>\n",
              "      <td>29</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>36</td>\n",
              "      <td>70</td>\n",
              "      <td>36.4</td>\n",
              "      <td>93.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "      <td>0.408</td>\n",
              "      <td>22</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>23</td>\n",
              "      <td>62</td>\n",
              "      <td>22.9</td>\n",
              "      <td>53.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>48</td>\n",
              "      <td>0.678</td>\n",
              "      <td>13</td>\n",
              "      <td>13.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>30.8</td>\n",
              "      <td>52.5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>68</td>\n",
              "      <td>0.122</td>\n",
              "      <td>32</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>25</td>\n",
              "      <td>78</td>\n",
              "      <td>36.1</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>0.496</td>\n",
              "      <td>29</td>\n",
              "      <td>29.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>25</td>\n",
              "      <td>52</td>\n",
              "      <td>28.5</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>115</td>\n",
              "      <td>1.699</td>\n",
              "      <td>22</td>\n",
              "      <td>2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>25</td>\n",
              "      <td>58</td>\n",
              "      <td>31.6</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>135</td>\n",
              "      <td>0.422</td>\n",
              "      <td>33</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>45</td>\n",
              "      <td>102</td>\n",
              "      <td>32.8</td>\n",
              "      <td>66.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>0.234</td>\n",
              "      <td>28</td>\n",
              "      <td>35.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>22</td>\n",
              "      <td>66</td>\n",
              "      <td>32.2</td>\n",
              "      <td>41.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.497</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>21</td>\n",
              "      <td>62</td>\n",
              "      <td>40.7</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>480</td>\n",
              "      <td>0.536</td>\n",
              "      <td>41</td>\n",
              "      <td>27.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>58</td>\n",
              "      <td>78</td>\n",
              "      <td>46.5</td>\n",
              "      <td>86.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>265</td>\n",
              "      <td>1.159</td>\n",
              "      <td>32</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>24</td>\n",
              "      <td>85</td>\n",
              "      <td>37.4</td>\n",
              "      <td>47.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0.247</td>\n",
              "      <td>25</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>26</td>\n",
              "      <td>64</td>\n",
              "      <td>28.6</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>140</td>\n",
              "      <td>0.411</td>\n",
              "      <td>35</td>\n",
              "      <td>23.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>26</td>\n",
              "      <td>66</td>\n",
              "      <td>23.6</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>0.666</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>22</td>\n",
              "      <td>58</td>\n",
              "      <td>21.8</td>\n",
              "      <td>50.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>90</td>\n",
              "      <td>0.155</td>\n",
              "      <td>35</td>\n",
              "      <td>31.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>24</td>\n",
              "      <td>80</td>\n",
              "      <td>34.8</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0.217</td>\n",
              "      <td>45</td>\n",
              "      <td>34.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>27</td>\n",
              "      <td>72</td>\n",
              "      <td>32.4</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>190</td>\n",
              "      <td>0.549</td>\n",
              "      <td>25</td>\n",
              "      <td>24.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>24</td>\n",
              "      <td>74</td>\n",
              "      <td>26.3</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>105</td>\n",
              "      <td>0.107</td>\n",
              "      <td>15</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>36</td>\n",
              "      <td>74</td>\n",
              "      <td>25.9</td>\n",
              "      <td>47.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>0.673</td>\n",
              "      <td>21</td>\n",
              "      <td>31.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>23</td>\n",
              "      <td>70</td>\n",
              "      <td>39.1</td>\n",
              "      <td>60.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>95</td>\n",
              "      <td>0.886</td>\n",
              "      <td>32</td>\n",
              "      <td>31.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>37</td>\n",
              "      <td>72</td>\n",
              "      <td>22.1</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>87</td>\n",
              "      <td>0.463</td>\n",
              "      <td>12</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>31</td>\n",
              "      <td>74</td>\n",
              "      <td>29.9</td>\n",
              "      <td>84.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>125</td>\n",
              "      <td>0.268</td>\n",
              "      <td>19</td>\n",
              "      <td>35.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>376 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age Blood_Pressure   BMI Plasma_level  Autoimmune_Disease Adverse_events  \\\n",
              "0    30             64  35.1           61                   1              1   \n",
              "1    22             74    30           40                   0              1   \n",
              "2    21             70  30.8           50                   0              0   \n",
              "3    23             64  34.9         59.5                   0              0   \n",
              "4    25             76  53.2           81                   1              0   \n",
              "5    25             62  25.1           45                   0              1   \n",
              "6    35             84    35           68                   1              5   \n",
              "7    22             78  34.6         43.5                   0              1   \n",
              "8    23             68  29.7           37                   0              3   \n",
              "9    23             86  45.5           51                   1              2   \n",
              "10   21             66  28.1         44.5                   0              1   \n",
              "11   28             70  31.6         81.5                   1              3   \n",
              "12   54             78  35.2           75                   1              7   \n",
              "13   25             68  31.9           42                   0              3   \n",
              "14   43             58    34           49                   0              6   \n",
              "15   42             78  46.7         40.5                   0              7   \n",
              "16   21             52  24.6         49.5                   0              2   \n",
              "17   25             58  27.7         63.5                   0              2   \n",
              "18   23             74  33.6         53.5                   0              2   \n",
              "19   26             88  43.3         90.5                   1              0   \n",
              "20   24             56  33.3         38.5                   0              1   \n",
              "21   24             64  33.2         58.5                   0              4   \n",
              "22   31             78  33.8         86.5                   1              3   \n",
              "23   22             60  37.2         43.5                   0              1   \n",
              "24   60             68  30.1         90.5                   1              8   \n",
              "25   51             72  25.8           83                   1              5   \n",
              "26   37             58  29.5           72                   0              4   \n",
              "27   41             74  29.9           52                   1              6   \n",
              "28   28             78    39         60.5                   0              1   \n",
              "29   21             62  22.1         69.5                   0              0   \n",
              "..   ..            ...   ...          ...                 ...            ...   \n",
              "346  23             62    24         55.5                   0              1   \n",
              "347  24             88  44.5           87                   1              2   \n",
              "348  23             82  40.6         76.5                   0              1   \n",
              "349  40             88  38.2           84                   1              7   \n",
              "350  33             50  27.1         59.5                   1              6   \n",
              "351  55             72  37.7         51.5                   0              6   \n",
              "352  24             54  30.9           53                   0              3   \n",
              "353  25             68  30.5           64                   1              0   \n",
              "354  57             76  37.5           98                   1              8   \n",
              "355  36             70  36.4         93.5                   1              3   \n",
              "356  23             62  22.9         53.5                   1              3   \n",
              "357  37             70  30.8         52.5                   0              6   \n",
              "358  25             78  36.1           58                   0              1   \n",
              "359  25             52  28.5           41                   0              2   \n",
              "360  25             58  31.6           72                   1              2   \n",
              "361  45            102  32.8         66.5                   1              1   \n",
              "362  22             66  32.2         41.5                   0              2   \n",
              "363  21             62  40.7         69.5                   0              1   \n",
              "364  58             78  46.5         86.5                   0              0   \n",
              "365  24             85  37.4         47.5                   1              0   \n",
              "366  26             64  28.6         69.5                   0              5   \n",
              "367  26             66  23.6           50                   0              1   \n",
              "368  22             58  21.8         50.5                   0              2   \n",
              "369  24             80  34.8           56                   0              1   \n",
              "370  27             72  32.4           64                   1              3   \n",
              "371  24             74  26.3           58                   0              3   \n",
              "372  36             74  25.9         47.5                   0              1   \n",
              "373  23             70  39.1         60.5                   0              2   \n",
              "374  37             72  22.1           58                   0              4   \n",
              "375  31             74  29.9         84.5                   1              3   \n",
              "\n",
              "    Drug_in_serum Liver_function Activity_test Secondary_test  \n",
              "0             156          0.692            32           12.7  \n",
              "1              60          0.527            11              0  \n",
              "2              50          0.597            26           22.6  \n",
              "3              92          0.725            18            1.8  \n",
              "4             100          0.759            56            3.6  \n",
              "5              59          1.268            18           16.8  \n",
              "6              88          0.286            41           34.1  \n",
              "7              32          0.101            27           31.4  \n",
              "8              45          0.293            28            1.8  \n",
              "9             120          0.127            36           30.6  \n",
              "10             94          0.167            23           31.2  \n",
              "11            105          0.268            18           16.6  \n",
              "12            126          0.692            29           14.5  \n",
              "13            106          0.591            30            9.5  \n",
              "14            190           0.43            33           14.3  \n",
              "15             48          0.261            40           17.3  \n",
              "16             94          0.637            15           17.3  \n",
              "17            275            1.6            24           16.4  \n",
              "18            100          0.404            30            7.9  \n",
              "19            510          0.222            44           16.7  \n",
              "20             56          1.251            30           11.5  \n",
              "21            120           0.23            27           10.7  \n",
              "22            185           0.97            39            2.4  \n",
              "23             75          0.509            37           25.9  \n",
              "24            495          0.615            36           12.1  \n",
              "25            175          0.587            19           10.5  \n",
              "26            140          0.287            28           24.4  \n",
              "27            156          0.722            18           29.4  \n",
              "28             74          0.261            39             19  \n",
              "29            210          0.207            17              0  \n",
              "..            ...            ...           ...            ...  \n",
              "346           182          0.138            13           35.4  \n",
              "347           120          0.646            37             20  \n",
              "348           485          0.687            42           20.2  \n",
              "349           321          0.787            42           31.6  \n",
              "350           176          1.318            22           27.7  \n",
              "351           190          0.324            32           18.7  \n",
              "352           158          0.292            21           11.8  \n",
              "353           180          1.391            19           26.4  \n",
              "354           280          0.605            29            1.2  \n",
              "355           200          0.408            22            6.7  \n",
              "356            48          0.678            13           13.8  \n",
              "357            68          0.122            32            1.3  \n",
              "358           180          0.496            29           29.9  \n",
              "359           115          1.699            22            2.7  \n",
              "360           135          0.422            33            4.7  \n",
              "361           140          0.234            28           35.2  \n",
              "362            50          0.497            23             16  \n",
              "363           480          0.536            41           27.7  \n",
              "364           265          1.159            32             12  \n",
              "365            36          0.247            25           10.8  \n",
              "366           140          0.411            35           23.1  \n",
              "367            56          0.666            15             24  \n",
              "368            90          0.155            35           31.5  \n",
              "369           132          0.217            45           34.6  \n",
              "370           190          0.549            25           24.1  \n",
              "371           105          0.107            15             23  \n",
              "372            73          0.673            21           31.6  \n",
              "373            95          0.886            32           31.3  \n",
              "374            87          0.463            12            0.5  \n",
              "375           125          0.268            19           35.5  \n",
              "\n",
              "[376 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9quyXUt1_VFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d20d1af-1ae7-4418-db6d-f96626802da4"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(376, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "OUI5fwFyZk84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split Train and Test"
      ]
    },
    {
      "metadata": {
        "id": "Kbp19FsAZuP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For any machine learning algorithm, the first task is to divide the data into test train dataset. This is because if we train the model using the entire dataset, the model would perform 100% accurate on the test data, but might not perform well on the new examples. Hence, we should split the data into test, train datasets and train the model using training dataset."
      ]
    },
    {
      "metadata": {
        "id": "zgjgJdoGaXVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fded7ade-64cc-4f63-c709-d6ed254a9abc"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = autoimmune_data.drop(columns = ['Autoimmune_Disease'])\n",
        "y = autoimmune_data['Autoimmune_Disease']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(282, 9)\n",
            "(94, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dJ5rmMWK7Eql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### kNN (k Nearest Neighbours)"
      ]
    },
    {
      "metadata": {
        "id": "bnt0fTo9mnHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c410834-7c6b-416c-c5fc-d9c3d7a516ab"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "autoimmune = KNeighborsClassifier(n_neighbors=5)\n",
        "autoimmune.fit(X_train, y_train)\n",
        "accuracy = autoimmune.score(X_test, y_test)\n",
        "print(\"The accuracy of the model using k=5 is {}\".format(accuracy))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model using k=5 is 0.7340425531914894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dIpH2C_wYRht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ]
    },
    {
      "metadata": {
        "id": "JJUDlkwcZkKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7af06650-07b7-4373-bfb6-d52372454fa5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(autoimmune, X, y, cv=10)\n",
        "print(scores)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.73684211 0.65789474 0.68421053 0.76315789 0.68421053 0.73684211\n",
            " 0.76315789 0.78947368 0.72222222 0.75      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnWjr-VwZ3GV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe31048-d3b0-43e7-9012-460c3014385e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Mean of 10-fold cross validation scores : {}\".format(scores.mean()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of 10-fold cross validation scores : 0.7288011695906433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kmZVbZZdaW15",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Selection - Finding optimal values of k"
      ]
    },
    {
      "metadata": {
        "id": "ztsCKgiCamw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "70a1bc41-867a-42ef-dc09-adf5adf64ed9"
      },
      "cell_type": "code",
      "source": [
        "k_range = range(1,20)\n",
        "k_scores = []\n",
        "for i in k_range:\n",
        "  autoimmune = KNeighborsClassifier(n_neighbors=i)\n",
        "  k_scores.append(cross_val_score(autoimmune, X, y, cv=10).mean())\n",
        "\n",
        "print(k_scores)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6861111111111111, 0.6942982456140352, 0.6916666666666667, 0.7261695906432748, 0.7288011695906433, 0.7421052631578947, 0.7501461988304092, 0.7635964912280702, 0.7529239766081871, 0.7421052631578948, 0.7554093567251462, 0.7605263157894736, 0.7605263157894736, 0.7364035087719298, 0.7549707602339181, 0.7467836257309942, 0.7549707602339182, 0.7521929824561403, 0.7548245614035088]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tq9p5cxKcSFa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the scores:"
      ]
    },
    {
      "metadata": {
        "id": "CFRzR6frcTsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2bfb80ff-e133-42cb-e6f6-21778086efb5"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('score')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f23f0d39f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2zEyU7h7c4Uc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above plot, the optimum value for k is 8."
      ]
    },
    {
      "metadata": {
        "id": "1DLcm8PJgirD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f0463f-17a6-4575-8830-077693e5e2ab"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn = KNeighborsClassifier(n_neighbors=8)\n",
        "accuracy_knn = cross_val_score(autoimmune_knn, X, y, cv=10).mean()\n",
        "print(\"Accuracy using knn is {}\".format(accuracy_knn))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using knn is 0.7635964912280702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5e-N3AVO8wrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalising the data"
      ]
    },
    {
      "metadata": {
        "id": "awoKHfxk6AAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy can be increased by normalising/scaling the data.\n",
        "\n",
        "**Scaling**:  Shifting the distribution of the data to have zero mean\n",
        "\n",
        "**Normalizing**: Rescaling the data into the range 0 to 1.\n",
        "\n",
        "In below example we are going to scale the data, i.e. make the mean of each column zero (or close to zero)"
      ]
    },
    {
      "metadata": {
        "id": "iaKxGuzo8107",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "eda9d473-3ce1-4c9a-8e2e-d8f693908037"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "X_scaled = preprocessing.scale(X)\n",
        " \n",
        "X_scaled.mean(axis=0) # axis=0 indicated that mean should be taken wrt col"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.11022302e-16,  3.68499557e-16,  0.00000000e+00,  0.00000000e+00,\n",
              "        7.08652994e-18,  6.37787695e-17,  9.44870659e-18,  3.77948264e-17,\n",
              "       -1.32281892e-16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "mCqx1GK2By_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not lets train the model using the scaled data"
      ]
    },
    {
      "metadata": {
        "id": "EmCQXl2h9NrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1a2cdea-eaad-42bd-d2b1-77dfb2347e62"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn = KNeighborsClassifier(n_neighbors=8)\n",
        "accuracy_knn = cross_val_score(autoimmune_knn, X_scaled, y, cv=10).mean()\n",
        "print(\"Accuracy using knn is {}\".format(accuracy_knn))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using knn is 0.7634502923976608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3oTeYQPCtVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now lets do the 10 fold cross validation on the normalised data. Instead of repeating the above loop for normalised data we will use GridSearchCV."
      ]
    },
    {
      "metadata": {
        "id": "naGzRxIGCbbW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GridSearchCV"
      ]
    },
    {
      "metadata": {
        "id": "1nxMCuwLCmUg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All the above tasks of running a with a range of k values and each time executing a 10-fold cross validation. This loop can be replace with GridSearchCV, which will do all the tasks in one statement."
      ]
    },
    {
      "metadata": {
        "id": "f3sGbgEMDDr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ah8O-ZG0DUtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "997c00cd-05e6-41ad-b0a7-a19c3026d1b0"
      },
      "cell_type": "code",
      "source": [
        "parm_grid = dict(n_neighbors=range(1, 20))\n",
        "print(parm_grid)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': range(1, 20)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8i2ZUA1zEemF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below GridSearchCV to execute the 10 fold cross validation for each value of k and fits the model with optimum k value."
      ]
    },
    {
      "metadata": {
        "id": "cDMoSK1dD7E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "9e81e43f-0546-460a-d0be-78374d81d359"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn_scaled = GridSearchCV(autoimmune_knn, parm_grid, cv=10)\n",
        "autoimmune_knn_scaled.fit(X_scaled, y)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score='raise',\n",
              "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
              "           weights='uniform'),\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'n_neighbors': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
              "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ro5pZIWFb_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "34aa0bcd-d346-4958-80a6-aabc561815ad"
      },
      "cell_type": "code",
      "source": [
        "print(\"Mean Scores\")\n",
        "print(autoimmune_knn_scaled.cv_results_['mean_test_score'])\n",
        "print(\"\\nStd deviation for each score\")\n",
        "print(autoimmune_knn_scaled.cv_results_['std_test_score'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Scores\n",
            "[0.69946809 0.73404255 0.76329787 0.75531915 0.77393617 0.76595745\n",
            " 0.76595745 0.76329787 0.75797872 0.73670213 0.75       0.74734043\n",
            " 0.75       0.75531915 0.75797872 0.75797872 0.75797872 0.76329787\n",
            " 0.76861702]\n",
            "\n",
            "Std deviation for each score\n",
            "[0.07939772 0.0645169  0.05071658 0.0589824  0.0473515  0.06529568\n",
            " 0.07559001 0.0748407  0.07450501 0.06015077 0.06160315 0.04501655\n",
            " 0.04678776 0.05377541 0.05267613 0.06193764 0.05652174 0.05071658\n",
            " 0.06566239]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9vkwjA6Ikbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "548d5e68-58b7-4778-f384-466b4067a74f"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best Score for normalised data : {} for {}\".format(autoimmune_knn_scaled.best_score_, autoimmune_knn_scaled.best_params_))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score for normalised data : 0.773936170212766 for {'n_neighbors': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2RNTDFb1GXjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "23212560-9872-49f6-ca1a-424b68b27f7c"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn_raw = GridSearchCV(autoimmune_knn, parm_grid, cv=10)\n",
        "autoimmune_knn_raw.fit(X, y)\n",
        "print(\"Mean Scores\")\n",
        "print(autoimmune_knn_raw.cv_results_['mean_test_score'])\n",
        "print(\"\\nStd deviation for each score\")\n",
        "print(autoimmune_knn_raw.cv_results_['std_test_score'])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Scores\n",
            "[0.68617021 0.69414894 0.69148936 0.72606383 0.7287234  0.74202128\n",
            " 0.75       0.76329787 0.75265957 0.74202128 0.75531915 0.7606383\n",
            " 0.7606383  0.73670213 0.75531915 0.74734043 0.75531915 0.75265957\n",
            " 0.75531915]\n",
            "\n",
            "Std deviation for each score\n",
            "[0.07074504 0.0535229  0.06917107 0.05215766 0.03976016 0.03469748\n",
            " 0.03477429 0.04503125 0.03752673 0.05095012 0.04172371 0.0378729\n",
            " 0.0521295  0.06448708 0.05409981 0.06716467 0.06250306 0.05368341\n",
            " 0.06419102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tGcQUpNIIeV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce73557-7123-43b6-b35b-e79c2b7b347c"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best Score for normalised data : {} for {}\".format(autoimmune_knn_raw.best_score_, autoimmune_knn_raw.best_params_))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score for normalised data : 0.7632978723404256 for {'n_neighbors': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bLqO--LMHTQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After applying various tunings to the model, an accuracy of 77.3 has been achieved with k=5 and normalizing the data."
      ]
    },
    {
      "metadata": {
        "id": "F6p3XTZKhLhb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "C8ZNANHahSO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d04a43cd-5463-4ee1-cb4e-55dc22129825"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "autoimmune_log_reg = LogisticRegression()\n",
        "accuracy_log_reg = cross_val_score(autoimmune_log_reg, X, y, cv=10).mean()\n",
        "print(\"Accuracy using Logistic Regression is {}\".format(accuracy_log_reg))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Logistic Regression is 0.7818713450292398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UrFjBokmiizY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above models, there is no signicant difference in accuracy between Logistic Regression and kNN, but Logistic Regression seems to perform better than kNN."
      ]
    }
  ]
}